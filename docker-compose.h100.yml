# Docker Compose for H100 GPU Deployment
# This configuration runs the full capitalism simulation with AI agents
# Requires: NVIDIA Docker runtime, H100 GPU
#
# USAGE:
#   # List your local models first:
#   ls ~/.cache/huggingface/hub/  # or wherever your models are
#
#   # Then run with your model:
#   LLM_MODEL=/models/your-model-name docker-compose -f docker-compose.h100.yml up -d
#
#   # Or for HuggingFace models:
#   LLM_MODEL=meta-llama/Llama-3.1-70B-Instruct docker-compose -f docker-compose.h100.yml up -d

version: '3.8'

services:
  # ============================================
  # vLLM Inference Server (H100)
  # ============================================
  vllm:
    image: vllm/vllm-openai:latest
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      - HF_TOKEN=${HF_TOKEN:-}
    ports:
      - "8080:8000"
    volumes:
      # Mount HuggingFace cache
      - ~/.cache/huggingface:/root/.cache/huggingface
      # Mount local models directory (if you have models stored elsewhere)
      - ${LOCAL_MODELS_PATH:-/tmp/placeholder}:/models
    command: >
      --model ${LLM_MODEL:-meta-llama/Llama-3.1-8B-Instruct}
      --tensor-parallel-size ${TENSOR_PARALLEL:-1}
      --max-model-len ${MAX_MODEL_LEN:-8192}
      --gpu-memory-utilization ${GPU_MEM_UTIL:-0.9}
      --enable-chunked-prefill
      --max-num-seqs 256
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s
    networks:
      - capitalism-net

  # ============================================
  # AI Agent Service
  # ============================================
  agent-service:
    build:
      context: ./services/agents
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    environment:
      - GATEWAY_URL=http://gateway:8000
      - LLM_PROVIDER=vllm
      - LLM_BASE_URL=http://vllm:8000
      - LLM_MODEL=${LLM_MODEL:-meta-llama/Llama-3.1-8B-Instruct}
      - BATCH_SIZE=${BATCH_SIZE:-20}
    volumes:
      - simulation-data:/app/simulation_data
    depends_on:
      vllm:
        condition: service_healthy
      gateway:
        condition: service_started
    networks:
      - capitalism-net

  # ============================================
  # Existing Services (from main docker-compose.yml)
  # ============================================
  frontend:
    build: ./frontend
    ports:
      - "3000:80"
    depends_on:
      - gateway
    networks:
      - capitalism-net

  gateway:
    build: ./gateway
    ports:
      - "8000:8000"
    depends_on:
      - redis
      - marketplace-1
      - marketplace-2
      - marketplace-3
      - discourse-1
      - discourse-2
      - discourse-3
    environment:
      - MARKETPLACE_REPLICAS=marketplace-1:3001,marketplace-2:3002,marketplace-3:3003
      - DISCOURSE_REPLICAS=discourse-1:4001,discourse-2:4002,discourse-3:4003
      - REDIS_URL=redis://redis:6379
      - JWT_SECRET=capitalism-simulation-secret-key-2025
      - CACHE_TTL=60
    networks:
      - capitalism-net

  marketplace-1:
    build: ./services/marketplace
    environment:
      - PORT=3001
      - MONGODB_URI=mongodb://mongo-marketplace:27017/marketplace
      - INSTANCE_ID=marketplace-1
    depends_on:
      - mongo-marketplace
    networks:
      - capitalism-net

  marketplace-2:
    build: ./services/marketplace
    environment:
      - PORT=3002
      - MONGODB_URI=mongodb://mongo-marketplace:27017/marketplace
      - INSTANCE_ID=marketplace-2
    depends_on:
      - mongo-marketplace
    networks:
      - capitalism-net

  marketplace-3:
    build: ./services/marketplace
    environment:
      - PORT=3003
      - MONGODB_URI=mongodb://mongo-marketplace:27017/marketplace
      - INSTANCE_ID=marketplace-3
    depends_on:
      - mongo-marketplace
    networks:
      - capitalism-net

  discourse-1:
    build: ./services/discourse
    environment:
      - PORT=4001
      - DATABASE_URL=postgres://postgres:password@postgres-discourse:5432/discourse
      - INSTANCE_ID=discourse-1
    depends_on:
      - postgres-discourse
    networks:
      - capitalism-net

  discourse-2:
    build: ./services/discourse
    environment:
      - PORT=4002
      - DATABASE_URL=postgres://postgres:password@postgres-discourse:5432/discourse
      - INSTANCE_ID=discourse-2
    depends_on:
      - postgres-discourse
    networks:
      - capitalism-net

  discourse-3:
    build: ./services/discourse
    environment:
      - PORT=4003
      - DATABASE_URL=postgres://postgres:password@postgres-discourse:5432/discourse
      - INSTANCE_ID=discourse-3
    depends_on:
      - postgres-discourse
    networks:
      - capitalism-net

  mongo-marketplace:
    image: mongo:6
    volumes:
      - mongo-marketplace-data:/data/db
    networks:
      - capitalism-net

  postgres-discourse:
    image: postgres:15
    environment:
      - POSTGRES_DB=discourse
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres-discourse-data:/var/lib/postgresql/data
    networks:
      - capitalism-net

  redis:
    image: redis:7-alpine
    volumes:
      - redis-data:/data
    networks:
      - capitalism-net

  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks:
      - capitalism-net

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3004:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - grafana-data:/var/lib/grafana
    networks:
      - capitalism-net

networks:
  capitalism-net:
    driver: bridge

volumes:
  mongo-marketplace-data:
  postgres-discourse-data:
  redis-data:
  prometheus-data:
  grafana-data:
  simulation-data:
